TODO stack
----------

* Reading/Writing serialized data should be done in C for better perfs.
  So give up GZip support, and implement a binInput able to read/write
  caml's ints, int32s, int64s, strings, varints, bools, and so on.
  Simple, Fast, easy to optimize.
  Problems: we do not want to give up reading from a string, and we want
  to compose higher level reader from lowel level ones.
  -> on n'implémente que des (dé)sérialiseurs pour les types de base, à
	 partir d'une zone mémoire qui contient soit le fichier soit une string
	 ocaml. Si les fichiers ne font qu'un Mo on peut même les mapper
	 entièrement.
  Note: pour les booleens, avoir un offset en bit aussi, qu'on remet à zéro
  à chaque fois qu'on doit lire un type aligné ; comme ca on peut packer
  plusieurs bits (ou valeurs à moins de 8 bits) ensemble.

* DB for traffic is too big. Packet counts, payloads, etc, should be variable 
ints (since they are usualy very small)

* An Interval type

* CGI: in traffic filters IPs should be a CIDR not InetAddr.

* It would be nice if any reasonably widespread date format were 
understood by Timestamp.read_txt. Or provide a helper function (for better
performances)

* junkie.scm: for http, add an intermediary state between query and answer
matching any packet belonging to this cnx in order to reset the timeout clock.

* Add the possibility to listen on any event in netmatch (like HTTP end of 
body)

* Add payload and its transfert time to web metric


* A repair tool (scanning files and reporting those that cannot be read,
  for later inspection/deletion, or offering to truncate the file (or merely
display file and offset where the error occured))


* Factorize DNS with WEB and ETH.


* Should print help when no cmdline arg is given

* A wrapper around Arg and Cgi to have either help/form or wrap the result
  of dump/load/... into a csv/svg

* SVG (and x11) version of dump command that performs one among several kind 
  of plots with given columns

* CGI version of dns.opt/web.opt (both Arg.parse or Cgi.parse_args, depending 
  of envvars!)


* More tests for the helper functions and the (de)serializers.


* Parallelize writing (less obvious but less useful).

For writing, either we allow anyone to append in any file, but then
the meta data must be merged somehow (might not be possible with some
aggregate function) ; or we allocate writers to some index value, the
forked writer being responsible for the meta data and the serialization,
but only a central writer performs the accumulations in the various Lods.


* In the same spirit than locking, write a file with the textual 
representation of the record type in a table directory (and check it when 
opening the table).


* Think of a way to ensure that when we compute a hash to select a part of
a table we actually hash the correct datatype (ie. Dns0.hash takes a full 
record, extract something then hash this, while Dns0.dump hash a server IP,
check that what Dns0.hash extract is also an IP). Additionally, simplify
the index handling (Dns0.dump is too complex wrt. index)


* Dump should be able to send output to a pipe (ssh compressed tunnel) for
distributed querying


Reference for gnuplot:
----------------------

- http://gnuplot-surprising.blogspot.fr/
- http://www.gnuplotting.org/
- http://gnuplot-tricks.blogspot.fr/

