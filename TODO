TODO stack
----------

- Make two pass algo output error margins as well, and result table display 
them, then have hitters produce same output, and let the user choose it's
scanning method (single or two passes)

- rename to netmine?

Reports
-------

- filters target should be Reports/save and hidden values in form should tell
report name and page_no of the submitted form ; then Reports/save should write 
the new params and re-run Reports/show. So, we should pass Ctrl.functions 
these additional parameters (target + set of additional hidden values)

- for easier saving of reports, replace conf file hierarchy with a simpler, 
single file, that's map_inplaced for certain keys when saved.


Bugs
----

- netgraph does not display when macs and/or ip are resolved?

- traffic/bandwidth: ask for a time interval of 10 minutes with a time step of 
  10 month consumes all memory and crash?!



Code specialization
-------------------

- in order for fold_all to be more useful, code a 
  User_filter.from_simple_filter taking the simple_filter field description in 
parameter (which field descriptions would come handy in www/my_form.ml)

- Find other opportunities to specialize some code (for instance use fold_all 
  to replace fold)


User_filter
-----------

- Negation in filters (for instance, ip not 1.2.3.4), aka free query
  or convert guided filters into free query, then admit an operator in
from of guided filter values ?



- code metrics to measure time spent in fold, group by...


- base 10 for choosing timestamps is not the best. See:
http://eneide.happyleptic.org/~rixed/mlrrd/?action=Traffic%2Fbandwidth&filter.start=-1month&filter.stop=-0d&filter.vlan=&filter.eth-src=&filter.eth-dest=&filter.eth-proto=&filter.ip-src=&filter.ip-dst=&filter.ip=eneide.happyleptic.org&filter.ip-proto=&filter.port=&filter.tstep=8h&filter.vol-table=2&filter.Y=0&filter.groupby=0&filter.series=&filter.start=1354386529.752809&filter.stop=1356079225.483146&filter.tstep=18703.8202247191&filter.start=1354854398.4538653&filter.stop=1356014560.6820674&filter.tstep=12819.47213483146&filter.start=1355332802.4229686&filter.stop=1356008042.9037416&filter.tstep=7461.220782022472&filter.start=1355917697.8783033&filter.stop=1355998119.7698314&filter.tstep=888.6396853932584

- Bandwidth chart : when using only ip (src or dst) filter, one would like
to group by 'other-ip'.



- Use logarithmic Y scale for primary Y in resp times vs time charts



Tables
------

- we only ever want to display the top N records (according to some field 
  value). As all datatype admit a comparison operator, then we can get the
  top (or bottom) N according to any field. Also, we'd like to have additional
  "virtual" fields (like geographic position).
- all fields that we do not want to see are aggregated (ie ignored)

- Add a sum line

- In sort by column, add a percent of total in parentheses

- Can mark a line by clicking on it


- An html legend next to the callflow svg, with y mouse coordinate translated
  into time, and info on selected peer timeline (IP...?) + http link to other
  infos related to this peer


- TCP resptimes

- Sort the table by sort_field before returning values


Traffic Map
-----------

- automatic center on graph boundary



User prefs
----------

- (key->value db in regular file) Une config permettant d'associer des 
  couleurs à des hosts (basé sur mac ou ip), et qu'on utiliserait pour colorer 
des lignes ou des nodes svg.

- Et une config pour nommer des filtres?

- Save under a given name some user defined graphs (such as: last_week_BW)

- LoD time aggregations should be configurable (and lod name as well)


- callflow: when mouse if over an arrow display time in legend

- Add user-agent and referer in web metric


- Add IP-server, IP-client in the various graphs were an IP is accepted
  (using the same simple way to find out which is which)

- Move in junkie the server discovery mechanism

- Add is_server + certainty bit in tcp_proto_info.


- Un graph pour les métriques HTTP/DNS qui permet de grapher en fonction du 
temps la volumétrie (soit nombre de requète, soit volume, soit durée) group by
un paramètre (ip src, ip dst, hostname, hostname+url, noms requit...)


- Un netgraph DNS et TCP

- Pour simplifier le netgraph, une métrique virtuelle avec :
  - vlan, mac+ip source, mac+ip dest, mac+ip proto (filtre: vlan, etc)
  - un type (dns, traffic, web, tcp...) (filtre: multiselect)
  - un nombre de requètes source vers dest (filtre: #query min)
  - un flag ok ou nok (filtre: ok/nok/both)
  - une string pour identifier quoi (agrégeable), en option (pour agréger 
	plus) (filtre: substring match + checkbox pour activer la collecte)
et c'est ça qu'on grapherait dans netgraph.


- Aussi pouvoir déclencher / récupérer des pcap?


- Filters for http method, vlan, etc, should be multiselect or
accept syntax such as "3,5,67-78", and these params should be returned
as functions. The only exception is ip srv which is used as an index.

- IP proto should be a selectbox


- in the netgraph legend, display roles or IPs, as the port the IP is server 
for (ie traffic decomposition by srv port - or a button to open a page with this info 
for this IP).

- in the netgraph legend, display MTU/traffic per link

- in the netgraph legend, client side search engine for IP/Mac

- Add metric for Sql, VoIP, ARP, ...

- Remove all non-ip traffic when we ask an IP peer graph

- Apart in places where we have Y per secs, keep integers instead of floats
  for volumes.


- A max packet size chart, as an histogram


- A metric for notifications (displayed on graphs and tables and netgraph (in 
a separate window), with restarts write new ones (added from junkie2db for 
instance)


- In all time charts where the selected period spans no more than 10 days,
display in chart background the night times with a sligh dark-blue bgcolor.

- Add a vertical bar at current time.


- junkie.scm: for http, add an intermediary state between query and answer
matching any packet belonging to this cnx in order to reset the timeout clock.

- Add the possibility to listen on any event in netmatch (like HTTP end of 
body)

- Add payload and its transfert time to web metric


- Fix multiple writer by flushing in O_APPEND after complete tuples

- To avoid crashing the files too often, flush at some safe points from time 
  to time (and not between safe points). Currently meta file is written every
  10 secs or so, in order to provide up to date values for readers - let's use
  this to additionaly flush the corresponding sequence to disk (using a new
  obuf_flush function, writing it's buffer and calling fdatasync)


- In the same spirit than locking, write a file with the textual 
representation of the record type in a table directory (and check it when 
opening the table).


- Think of a way to ensure that when we compute a hash to select a part of
a table we actually hash the correct datatype (ie. Dns0.hash takes a full 
record, extract something then hash this, while Dns0.dump hash a server IP,
check that what Dns0.hash extract is also an IP). Additionally, simplify
the index handling (Dns0.dump is too complex wrt. index)


- Dump should be able to send output to a pipe (ssh compressed tunnel) for
distributed querying


- nettrack language should provide special function to create a new capfile,
  add a packet to it, discard it, save it, etc. Ie. a capture type with most
  operations implemented in C.


- an indexer process that adds N.idx to N files once closed, to speed up 
  searches in the past.


- distrib chart for HTTP should give choice for grouping field (for instance,
  response code, method...)


- a tuple from 1hour table (traffic) which is 2 hours long:
  "2012-12-29 21:00        2012-12-29 23:00        ..."

